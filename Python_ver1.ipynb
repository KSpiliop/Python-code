{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "from scipy import stats\n",
    "import string\n",
    "import itertools as it\n",
    "import timeit\n",
    "import datetime \n",
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpath = 'D:\\\\Kimon\\\\Documents\\\\Quantos-new\\\\z90-030\\\\Python code'\n",
    "os.chdir(wpath)\n",
    "current_time = datetime.datetime.now() \n",
    "outfiles_s = str(current_time.month)+ '_' + str(current_time.day) + \\\n",
    "                                      '_'+str(current_time.hour) + \\\n",
    "                                      '_'+str(current_time.minute)\n",
    "\n",
    "KAPPA = 3 ; H = 3\n",
    "flog = open(wpath + '\\\\log.txt', \"w\") \n",
    "FILE = \"declaration_remuneration_2020_07_16_04_00.csv\" ##\"newdata2_del.csv\"\n",
    "ALPHA = 0.05\n",
    "V1 = 0.99 ; V2 = 0.999\n",
    "DROP_VARS = ['ligne_identifiant','remu_convention_liee'] ## or an empty list\n",
    "DROP_VARS_PERC = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymise(inp, k): \n",
    "  ## perform heuristic k-anonymization on a dataset inp\n",
    " \n",
    "    N, M = inp.shape\n",
    "    dataCode = np.zeros((N,M),dtype=int)\n",
    "    for c in range(M): \n",
    "        print('c= ',c)\n",
    "        t1_idx = np.argsort(inp[:,c])\n",
    "        t1 = inp[t1_idx,c]\n",
    "        kq = np.empty((N,),dtype = np.int)\n",
    "        i = 0\n",
    "        sPT = 1 ## counter for row i\n",
    "        group = 1 ## current group\n",
    "        kq[0] = group ## assignment of row i\n",
    "        n = len(t1)\n",
    "        while i < n-1:\n",
    "        #for i in range(1,n-1):    \n",
    "            i += 1\n",
    "            sPT += 1\n",
    "            ## initialize new group if new value met and\n",
    "            ## capacity of group is exceeded \n",
    "            if (sPT > k) and (t1[i]!=t1[i-1]): \n",
    "                group += 1\n",
    "                sPT += 1\n",
    "            kq[i] = group\n",
    "    \n",
    "        ## make last elements consistent\n",
    "        if kq[n - 2] != kq[n - 3]:\n",
    "            kq[n - 2] = kq[n - 3]\n",
    "            kq[n - 1] = kq[n - 3]\n",
    "        if kq[n - 1] != kq[n - 2]:\n",
    "            kq[n - 1] = kq[n - 3]\n",
    "\n",
    "        a3 = np.zeros(N,dtype = np.int)\n",
    "        a3[t1_idx] = np.arange(N)\n",
    "        dataCode[:,c] = kq[a3]\n",
    "        \n",
    "    return dataCode \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_re(inp,h):\n",
    "    C = comb(len(inp.columns),3)\n",
    "    res=[None]*C ; i=0 ; N = len(inp)\n",
    "    start_time = timeit.default_timer()\n",
    "    combins = [c for c  in it.combinations(inp.columns,3)]\n",
    "    print(len(combins))\n",
    "    for combin in combins:\n",
    "        i += 1  \n",
    "        #x = sum(rle_encoding(np.array(inp.groupby(list(comb),sort=True).size())))/N\n",
    "        x = sum(pd.value_counts(inp.groupby(list(combin),sort=False).size(),\n",
    "                            sort=False,dropna=False))/N\n",
    "        #x = len(inp.groupby(list(comb),sort=False).nunique())/N\n",
    "        #x = sum(np.bincount(inp.groupby(list(comb),sort=False).size()))/N\n",
    "        #x = sum(Counter(inp.groupby(list(comb),sort=False).size()).values())/N\n",
    "        if i % 100 == 0: print(i,x)\n",
    "        res[i-1] = (combin,x)\n",
    "    print('\\nTime in prob_re(): {0:12.2f} secs\\n'.format(timeit.default_timer() - start_time))\n",
    "     \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read FILE and fill missing values with \"NA\" \n",
    "* Check unique values and delete columns in DROP_VARS or if DROP_VARS is empty, delete variables with unique values $\\geq$ DROP_VARS_PERC x number of rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(FILE,sep=';',dtype=object,low_memory=False)\n",
    "data.fillna(value='NA', inplace=True)\n",
    "data.isna().sum()\n",
    "\n",
    "to_delete=list()\n",
    "for col in data.columns:\n",
    "    unis = len(pd.unique(data[col]))\n",
    "    print('\\n{0:30s} \\nUnique values: {1:8d}'.format(col,len(pd.unique(data[col]))),end='')\n",
    "    try:\n",
    "        print('\\n{0:30s} \\nUnique values: {1:8d}'.format(col,len(pd.unique(data[col]))),end='',file=flog)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if unis >= DROP_VARS_PERC*len(data): \n",
    "        print('     *****')\n",
    "        try:\n",
    "            print('     *****',file=flog)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        to_delete.append(col)\n",
    "    else:\n",
    "        print()\n",
    "\n",
    "print('\\nDeleting variables:\\n')                \n",
    "if len(DROP_VARS) > 0:        \n",
    "    print(to_delete)\n",
    "    print('*** Overriden:')\n",
    "    print(DROP_VARS)\n",
    "    data.drop(labels=DROP_VARS, axis=1, inplace=True)    \n",
    "else:\n",
    "    print(to_delete)\n",
    "    data.drop(labels=to_delete, axis=1, inplace=True)    \n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms = data.columns\n",
    "N,M = data.shape\n",
    "np_data = np.zeros((N,M),dtype=int)\n",
    "for c in range(len(data.columns)):\n",
    "    np_data[:,c], _ = pd.factorize(data.iloc[:,c])\n",
    "    #print('\\n{0:2d} Unique values: {1:8d}'.format(c,len(pd.unique(np_data[:,c]))))\n",
    "    try:\n",
    "        print('\\n{0:2d} Unique values: {1:8d}'.format(c,len(pd.unique(np_data[:,c]))),file=flog)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np_data).to_csv('np_data'+outfiles_s+'.csv',sep=';')\n",
    "anon = anonymise(np_data, k=KAPPA)\n",
    "anon = pd.DataFrame(anon,columns=data.columns)\n",
    "anon.to_csv('anon'+outfiles_s+'.csv',sep=';')\n",
    "anon\n",
    "\n",
    "results = prob_re(anon,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_out = sorted(results,key=itemgetter(1),reverse=True)\n",
    "topn = round(ALPHA*len(results))\n",
    "res_out = res_out[:topn]\n",
    "_, probs_out = zip(*res_out)\n",
    "\n",
    "top_probs = pd.DataFrame(res_out,columns=['Combination','Probability'])  \n",
    "top_probs\n",
    "\n",
    "#_ = plt.hist(probs_out,bins=50)\n",
    "#_ = plt.grid(True)\n",
    "#plt.show()\n",
    "\n",
    "flog.close()\n",
    "\n",
    "_ = top_probs['Probability'].plot(kind='hist', bins=50, grid = True, figsize=(6,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, probs = zip(*results)\n",
    "probs = [p for p in probs]\n",
    "\n",
    "_ = plt.hist(probs,bins=50)\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of probability of re-identification')\n",
    "_ = plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "flog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GPD_PWM(excesses): \n",
    "    a0 = np.mean(excesses)\n",
    "    x_s = sorted(excesses) ; n = len(x_s)\n",
    "    kappas = np.arange(1,n+1) \n",
    "    product = (n-kappas)/(n-1)\n",
    "    a1 = np.multiply(x_s,product)\n",
    "    a1 = np.mean(a1)\n",
    "    shape = 2 - a0/(a0 - 2 * a1)\n",
    "    scale = max((2 * a0 * a1) / (a0 - 2 * a1),np.finfo(float).eps)\n",
    "    return (shape,scale)\n",
    "\n",
    "def id_danger(x ,v, alpha): \n",
    "    ## calculate the distribution of the (1-alpha) largest values, alpha = 0.95\n",
    "    ## v = 0.99 or 0.999\n",
    "  \n",
    "    ## all values of the distribution\n",
    "    ## in vector  x of length nx, sorted ascending in x_sort\n",
    "    nx = len(x)\n",
    "    x_sort = np.sort(x)    \n",
    "\n",
    "    nx_ex = round(alpha * len(x)) ## will keep approx. nx_ex largest values\n",
    "    id_u  = nx - nx_ex + 1 ## will drop id_u values\n",
    "    u  = x_sort[id_u] ## cut-off\n",
    "    \n",
    "    id_ex = np.where(x >= u) ## which values of x to keep\n",
    "    ## put these values in vector x_ex of length Nu\n",
    "    x_ex = x[x >= u]\n",
    "    Nu = len(x_ex)\n",
    "    \n",
    "    p_exceed = (x_ex > u).mean() # <- mean(x.ex > u) ## the proportion actually exceeding u\n",
    "    \n",
    "    ## fit to GPD and extract parameters xi (csi) and beta (shape and scale)\n",
    "    \n",
    "    (xi, beta) = fit_GPD_PWM(x_ex-u)\n",
    "    ##print('shape= ',xi)\n",
    "    ##print('scale= ',beta)\n",
    "\n",
    "      \n",
    "    ## the POT estimator - see p.7 top\n",
    "    ## = the T(k,1-v) value: \n",
    "    ## 1% or 0.1% of size k quasi-identifiers will have a probability of re-identification greater than this value\n",
    "    x_hat = u + beta / xi * ((nx / Nu * (1 - v)) ** (-xi) - 1)\n",
    "  \n",
    "    rl = dict()\n",
    "    rl['sort'] = x_sort\n",
    "    rl['value_extreme'] = x_ex\n",
    "    rl['index_extreme'] = id_ex\n",
    "    rl['p_exceed'] = p_exceed\n",
    "    rl['obs'] = nx\n",
    "    rl['Nb_extremes'] = Nu\n",
    "    rl['threshold'] = u,\n",
    "    rl['index.threshold'] = id_u,\n",
    "    rl['shape'] = xi,\n",
    "    rl['scale'] = beta,\n",
    "    rl['POT'] = x_hat\n",
    "    \n",
    "    return rl\n",
    "  \n",
    "def id_danger_logit(x, v1, v2, alpha): \n",
    "  \n",
    "    ## at level 1%\n",
    "    res  = id_danger(x, v1, alpha)\n",
    "    p99 = res['POT'] ## the temperature: 1% of size-k pseudo-identifiers\n",
    "    ## will have a probability of re-identification greater than this value\n",
    "    xi = res['shape']\n",
    "    beta = res['scale']\n",
    "    ##--------------------\n",
    "  \n",
    "    ## at level 0.1%\n",
    "    res = id_danger(x, v2, alpha)\n",
    "    p999 = res['POT']\n",
    "    ## --------------------\n",
    "  \n",
    "    ## logit, 1%\n",
    "    xx = np.log(x / (1 - x))\n",
    "    res = id_danger(xx, v1, alpha)\n",
    "    pi99 = res['POT']\n",
    "    xi_logit =  res['shape']\n",
    "    beta_logit =  res['scale']\n",
    "    p99_logit = np.exp(pi99) / (1 + math.exp(pi99)) ## temperature\n",
    "    ## --------------------\n",
    "  \n",
    "    ## logit, 0.1%\n",
    "    res = id_danger(xx, v2, alpha)\n",
    "    pi999 = res['POT']\n",
    "    p999_logit = np.exp(pi999) / (1 + np.exp(pi999)) ## temperature\n",
    "  \n",
    "    rl = dict()\n",
    "    rl['xi'] = xi\n",
    "    rl['beta'] = beta    \n",
    "    rl['xi_logit'] = xi_logit\n",
    "    rl['beta_logit'] = beta_logit    \n",
    "    rl['id_99'] = p99\n",
    "    rl['id_999'] = p999\n",
    "    rl['id_99_logit'] = p99_logit\n",
    "    rl['id_999_logit'] = p999_logit\n",
    "\n",
    "    return rl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(probs)\n",
    "\n",
    "results = id_danger(x ,V1, ALPHA)\n",
    "print(results)\n",
    "\n",
    "\n",
    "tmp = pd.DataFrame(x_ex-u,columns=['Excess'])\n",
    "_ = tmp['Excess'].plot(kind='hist', bins=50, grid = True, figsize=(6,4))\n",
    "\n",
    "res = id_danger_logit(x, v1=V1, v2=V2, alpha=ALPHA) \n",
    "\n",
    "print('       {0:6.1f}% quantile of extreme values: {1:8.4f}'.format(100*V1,\n",
    "              round(res['id_99'],4)))\n",
    "print('       {0:6.1f}% quantile of extreme values: {1:8.4f}'.format(100*V2,\n",
    "              round(res['id_999'],4)))\n",
    "print('Logit: {0:6.1f}% quantile of extreme values: {1:8.4f}'.format(100*V1,\n",
    "              round(res['id_99_logit'],4)))\n",
    "print('Logit: {0:6.1f}% quantile of extreme values: {1:8.4f}'.format(100*V2,\n",
    "              round(res['id_999_logit'],4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculations <- function(x,v1,v2,alpha) {\n",
    "\n",
    "#  tms <- id.danger(x, v1, alpha)\n",
    "#  xi <- round(tms$shape, 4) ## xi: shape\n",
    "#  beta <- round(tms$scale, 4) ## beta: beta\n",
    "#  u <- tms$threshold ## u: threshold with v1,alpha\n",
    "#  ex <- tms$value.extreme # extreme values\n",
    "  \n",
    "#  \n",
    "#  logit = log(x / (1 - x))\n",
    "#  tms2 <- id.danger(logit, v1, alpha)\n",
    "#  xi2 <- round(tms2$shape, 4) ## xi2: shape - logit\n",
    "#  beta2 <- round(tms2$scale, 4) ## beta2: scale - logit\n",
    "#  xh1 <- tms2$POT\n",
    "#  xhat1 <- exp(xh1) / (1 + exp(xh1))   # POT estimate with v1/logit\n",
    "\n",
    "#  xh2 <- id.danger(logit, v2, alpha)$POT\n",
    "#  xhat2 <- exp(xh2) / (1 + exp(xh2)) # POT estimate with v2/logit\n",
    "  \n",
    "#  xx <- seq(from = 0,to = 1,length = 1000)\n",
    "#  z <- qgpd(xx, xi, u, beta) ## z: quantiles from qgpd()\n",
    "#  y <- pgpd(z, xi, u, beta) ## y: probabilities from pgpd()\n",
    "  \n",
    "#  u1 <- id.danger(x, v1, 1 - v1)$threshold # u1: threshold with v1 and alpha = 1-v1\n",
    "#  u2 <- id.danger(x, v2, 1 - v2)$threshold # u2: threshold with v2 and alpha = 1-v2\n",
    "#  mep <- mean_excess_np(x) ## mean excess\n",
    "  \n",
    "  \n",
    "  ## res <- list(ex=ex,y=y,z=z,xi=xi,beta=beta,xi2=xi2,beta2=beta2,u=u,u1=u1,u2=u2,\n",
    "  ## mep=mep,xhat1=xhat1,xhat2=xhat2)\n",
    "  ## ex: extreme values \n",
    "  ## y: probabilities from pgpd()\n",
    "  ## z: quantiles from qgpd()\n",
    "  ## xi: shape\n",
    "  ## beta: beta\n",
    "  ## xi2: shape - logit\n",
    "  ## beta2: scale - logit\n",
    "  ## u: threshold with v1,alpha \n",
    "  ## u1: threshold with v1 and alpha = 1-v1\n",
    "  ## u2: threshold with v2 and alpha = 1-v2\n",
    "  ## mep <- mean_excess_np(x) ## mean excess\n",
    "  ## u1: threshold with v1 and alpha = 1-v1\n",
    "  ## u2: threshold with v2 and alpha = 1-v2\n",
    "  ## xhat1: POT estimate with v1/logit\n",
    "  ## xhat2: POT estimate with v2/logit\n",
    "#  \n",
    "#  res <- list(ex=ex,y=y,z=z,xi=xi,beta=beta,xi2=xi2,beta2=beta2,u=u,u1=u1,u2=u2,\n",
    "#              mep=mep,xhat1=xhat1,xhat2=xhat2)\n",
    "#  return(res)\n",
    "\n",
    "\n",
    "#}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
